NADS: AI STUDY COMPANION - INTERACTIVE DOCUMENT ANALYSIS & TUTOR

Version 1

NADS (AI Study Companion) is an intelligent, multimodal learning assistant that helps users study, explore topics, and test their understanding through quizzes, voice interaction, and document-based learning. It combines large language models, retrieval-augmented generation (RAG), web search, and speech features into a single interactive application.

The app is built with Streamlit for the frontend and Python for the backend, with flexible support for both cloud-based and local LLMs.

## Key Capabilities

Chat-based learning with AI
PDF-based question answering using RAG
Automatic quiz generation and evaluation
Web search and scraping for live educational content
Voice input (speech-to-text) and voice output (text-to-speech)
Downloadable AI-generated content as PDFs
Model evaluation using standard NLP metrics

## Tech Stack

Frontend:
Streamlit â€“ Interactive web application UI
Custom CSS â€“ Enhanced styling and layout control

Backend / Core Logic:
Python 3.x â€“ Core language
python-dotenv â€“ Environment variable and API key management

AI & NLP:
Google Gemini (google-generativeai, langchain-google-genai) â€“ Primary LLM for chat, summarization, and quiz generation
LangChain â€“ Prompt management, LLM chaining, and RAG orchestration
Ollama (langchain-ollama) â€“ Local embedding and LLM support
Sentence Transformers â€“ Text embeddings for semantic search

Retrieval-Augmented Generation (RAG):
FAISS â€“ Fast vector similarity search
pypdf â€“ PDF text extraction

Quiz System:
Custom Python modules â€“ Quiz generation, scoring, and feedback

Web Scraping & Search:
SerpAPI â€“ Google search restricted to educational sources
BeautifulSoup â€“ HTML parsing and content extraction

Voice Features:
SpeechRecognition â€“ Speech-to-text
pyttsx3 â€“ Text-to-speech
pyaudio â€“ Microphone and audio processing

PDF Generation:
ReportLab â€“ Create downloadable, formatted PDFs

Parsers:
mistune, html2text â€“ Markdown, HTML, and text conversion

Evaluation & Testing:
rouge-score â€“ Text generation evaluation
scikit-learn â€“ Similarity metrics and evaluation utilities

## Features

Dual Knowledge Modes
Document Mode (With PDFs)
Extracts text from uploaded PDFs
Generates embeddings and stores them in FAISS
Answers questions using retrieval-augmented generation
Live Mode (Without PDFs)
Performs real-time web search and scraping
Filters and summarizes educational content
Provides concise, relevant answers with references
Intelligent Context Switching
The system automatically decides whether to use document-based retrieval or live web data based on user input and available resources.
Quiz Generation and Evaluation
Automatically generates quizzes from PDFs or topics
Evaluates answers and provides feedback
Supports scoring and performance analysis
Voice-Enabled Interaction
Accepts spoken queries through a microphone
Responds with natural-sounding voice output
Improves accessibility and engagement
Model Evaluation
Uses ROUGE and cosine similarity metrics
Helps assess response quality and relevance

## Project Structure

AI-Tutor/
â”œâ”€â”€ aiFeatures/
â”‚ â”œâ”€â”€ **pycache**/
â”‚ â”œâ”€â”€ quiz_system.cpython-313.pyc
â”‚ â””â”€â”€ python/
â”‚ â”œâ”€â”€ ai_assistant.py               # Core decision-making and query routing
â”‚ â”œâ”€â”€ ai_response.py                # LLM response handling
â”‚ â”œâ”€â”€ evaluation.py                 # Model evaluation logic
â”‚ â”œâ”€â”€ evaluation_dataset.py         # Evaluation datasets
â”‚ â”œâ”€â”€ quiz_system.py                # Quiz generation and scoring
â”‚ â”œâ”€â”€ rag_pipeline.py               # RAG pipeline implementation
â”‚ â”œâ”€â”€ speech_to_text.py             # Voice input handling
â”‚ â”œâ”€â”€ text_to_speech.py             # Voice output handling
â”‚ â”œâ”€â”€ web_scraper_tool.py           # Search and scraping utilities
â”‚ â””â”€â”€ web_scraping.py               # Web content extraction
â”‚
â”œâ”€â”€ data/                           # Stored data and intermediate outputs
â”œâ”€â”€ env/                            # Virtual environment (optional)
â”œâ”€â”€ .env                            # API keys and environment variables
â”œâ”€â”€ .gitignore                      # Git ignore rules
â”œâ”€â”€ app.py                          # Streamlit application entry point
â”œâ”€â”€ README.md                       # Project documentation
â””â”€â”€ requirements.txt                # Python dependencies

## Use Cases

Students studying from textbooks or PDFs
Self-learners exploring new topics
Educators generating quizzes and summaries
Voice-based hands-free learning

## Future Enhancements

User authentication and progress tracking
Multi-language support
Persistent vector storage
Advanced analytics dashboard

## License

This project is intended for educational and research purposes.

## Getting Started

cd AI-Tutor

## Set Up Virtual Environment

python -m venv env
source env/bin/activate  # or env\Scripts\activate on Windows

## Install Dependencies

pip install -r requirements.txt

## Configure Environment Variables

Create a `.env` file and add:

GEMINI_API_KEY="your_gemini_key"
SERP_API_KEY="your_serpapi_key"
OLLAMA_MODEL=mxbai-embed-large

## Run the Application

streamlit run app.py
Streamlit will display the local URL in the terminal (usually http://localhost:8501).

## Ollama Setup

To use **Ollama embeddings** for document chunking and vector representation, follow these steps:

### 1. Install Ollama

Download and install Ollama from the official site:

ðŸ‘‰ [https://ollama.com/download](https://ollama.com/download)

After installation, ensure it is accessible in your terminal:

ollama --version

### 2. Pull the Required Model

Pull a supported embedding model like `mxbai-embed-large` or any other compatible model:

ollama pull mxbai-embed-large

### 3. Start Ollama Server (if required)

Ollama typically runs as a background service. If not, you can start it manually:

ollama serve

### 4. Integration in AI Tutor

The application uses Ollama to embed chunks of PDF/text using:

- `mxbai-embed-large` or any embedding model you configure
- Embeddings are stored in FAISS vector store and used for cosine similarity-based retrieval

Ensure your `.env` or config file includes proper references to use Ollama embeddings.

OLLAMA_MODEL=mxbai-embed-large

Youâ€™re now ready to use Ollama with AI TutorðŸŒŸ

